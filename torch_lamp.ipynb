{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_lamp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0bkeETfN5vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wopyurh2aZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr42Cg2G7uwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AMP_layer(nn.Module): #this is the pwlin AMP implementation of found on boergerding et al, \n",
        "  def __init__(self, A,device=device):\n",
        "   super(AMP_layer,self).__init__()\n",
        "   self.N= A.shape[1]\n",
        "   self.M= A.shape[0]\n",
        "   self.A_t= nn.Parameter(torch.tensor(A, device= device,requires_grad=True).float())\n",
        "   self.A_p= nn.Parameter(torch.tensor(A.T, device= device, requires_grad=False).float())\n",
        "   self.theta_0=nn.Parameter(torch.tensor(1.0,device= device,requires_grad=True))\n",
        "   self.theta_1= nn.Parameter(torch.tensor(1.0,device= device,requires_grad=True))\n",
        "   self.theta_2=nn.Parameter(torch.tensor(1.0,device= device,requires_grad=True))\n",
        "   self.theta_3=nn.Parameter(torch.tensor(1.0,device= device,requires_grad=True))\n",
        "   self.theta_4=nn.Parameter(torch.tensor(1.0,device= device,requires_grad=True))\n",
        "   self.beta=nn.Parameter(torch.tensor(1.0,device= device,requires_grad=True))\n",
        "  \n",
        "  def non_linearity(self,r,rvar,theta): # a general non-linearity would \n",
        "   ab0 = theta[0]                       #need to have inputs (r, variance_estimator, params_list)\n",
        "   ab1 = theta[1]                       # and outputs of form (xhat, dvtv of vector xhat wrt vector r)\n",
        "   sl0 = theta[2]\n",
        "   sl1 = theta[3]\n",
        "   sl2 = theta[4]\n",
        "\n",
        "   # scale each column by sqrt(rvar)\n",
        "   scale_out = torch.sqrt(rvar)\n",
        "   scale_in = 1/scale_out\n",
        "   rs = torch.sign(r*scale_in)\n",
        "   ra = torch.abs(r*scale_in)\n",
        "   \n",
        "   # split the piecewise linear function into regions\n",
        "   rgn0 = ( ra<ab0).float()#type(torch.FloatTensor)\n",
        "   rgn1 = (( ra<ab1).float() - rgn0)#type(torch.FloatTensor)\n",
        "   rgn2 = ( ra>=ab1).float()#type(torch.FloatTensor)\n",
        "   xhat = scale_out * rs*(\n",
        "          rgn0*sl0*ra +\n",
        "          rgn1*(sl1*(ra - ab0) + sl0*ab0 ) +\n",
        "          rgn2*(sl2*(ra - ab1) +  sl0*ab0 + sl1*(ab1-ab0) )\n",
        "          )\n",
        "   dxdr =  sl0*rgn0 + sl1*rgn1 + sl2*rgn2\n",
        "   \n",
        "   dxdr = torch.mean(dxdr,1, keepdim=True)\n",
        "   \n",
        "   return (xhat,dxdr)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "        \n",
        "        r= inputs[0]+torch.mm(inputs[1],self.A_t)\n",
        "        nor= (torch.norm(inputs[1],dim=-1,keepdim=True))**2\n",
        "        x_hat, dxdr= self.non_linearity(r,nor, [self.theta_0, self.theta_1,self.theta_2,self.theta_3,self.theta_4,])\n",
        "        v= inputs[2]- torch.mm(x_hat,self.A_p) + self.beta*dxdr*self.N/self.M*inputs[1]\n",
        "        return (x_hat,v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl1OvXmHMVaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model_AMP(nn.Module):                             #constructs a meta-module\n",
        "  def __init__(self, A,num_layers=7):                   #outputs a list of tensors\n",
        "    super(Model_AMP,self).__init__()                    #each of  which can be input to loss function\n",
        "    self.num_layers= num_layers\n",
        "    self.model_list= [None]*num_layers\n",
        "    for i in range(0, self.num_layers):\n",
        "      self.model_list[i]=AMP_layer(A)\n",
        "    self.outputs= [None]*self.num_layers\n",
        "   \n",
        "  def forward(self,inputs,):\n",
        "    i_layer=0\n",
        "    self.outputs[0]= self.model_list[0](inputs)\n",
        "    for i_layer in range(1,self.num_layers):\n",
        "      self.outputs[i_layer]=self.model_list[i_layer]([self.outputs[i_layer-1][0],self.outputs[i_layer-1][1],inputs[2]])\n",
        "    return self.outputs\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO6Cy6cTBm0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N=500\n",
        "num_epochs=100\n",
        "M=int(0.5*N)\n",
        "A= np.random.randn(M,N)/M**0.5\n",
        "rho=0.05#sparsity level\n",
        "snr_dB=40\n",
        "noise_scale=10**(-snr_dB/10)\n",
        "num_layers=10\n",
        "model_AMP= Model_AMP(A, num_layers).to(device)\n",
        "\n",
        "def data_gen(n_sims,A=A,snr=40,rho=0.11):\n",
        "    N= A.shape[1]\n",
        "    M= A.shape[0]\n",
        "    mask_vecs=np.random.binomial(1,rho,size=(n_sims,N))#*np.random.exponential(scale=1, size=(N,n_sims))\n",
        "    x_true_all= mask_vecs**0.5*np.random.randn(n_sims,N)\n",
        "    noise_scale=10**(-snr/10)\n",
        "    y_all= x_true_all@A.T + noise_scale**0.5*np.random.randn(n_sims,M)/(M**0.5)\n",
        "    n_sims_1=int(n_sims/100)\n",
        "    gamma_vecs_1=np.random.binomial(1,rho,size=(n_sims_1,N))\n",
        "    x_true_all_vali= gamma_vecs_1**0.5*np.random.randn(n_sims_1,N)\n",
        "    y_all_vali= x_true_all_vali@A.T + 10**(-snr*0.5/10)*np.random.randn(n_sims_1,M)*((rho*N/M)**0.5)\n",
        "    input_x_1=np.zeros_like(x_true_all_vali)\n",
        "    return x_true_all, y_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u2tzjnpUU71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%capture\n",
        "snr_train=40\n",
        "x_true_all_, y_all_= data_gen(1000,snr=snr_train)\n",
        "x_true_all=torch.from_numpy(x_true_all_).float().to(device)\n",
        "y_all=torch.from_numpy(y_all_).float().to(device)\n",
        "y_all_zero=torch.from_numpy(0*y_all_).float().to(device)\n",
        "input_x=torch.from_numpy(np.zeros_like(x_true_all_)).float().to(device)\n",
        "#input_x_1=torch.from_numpy(np.zeros_like(x_true_all_vali)).float().to(device)\n",
        "#out_list=model_AMP([input_x,y_all,y_all])\n",
        "\n",
        "optim_list= [None]*num_layers\n",
        "lr_1=3e-2\n",
        "lr_2= 8e-3\n",
        "lr= lr_1\n",
        "for i in range(num_layers):\n",
        "  if i >=2:\n",
        "    lr= lr_2\n",
        "  optim_list[i]=torch.optim.Adam(model_AMP.model_list[i].parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSFbRUvvgE56",
        "colab_type": "code",
        "outputId": "b2e564a0-baa9-4984-fec2-24f81d69ba39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# %%time\n",
        "# %%capture\n",
        "torch.cuda.empty_cache()\n",
        "num_epochs=500\n",
        "for i_layer in range(num_layers):\n",
        "  opt= optim_list[i_layer]\n",
        "  criterion = nn.MSELoss()\n",
        "  for i_epoch in range(num_epochs):\n",
        "    opt.zero_grad()\n",
        "    x_true_all_, y_all_= data_gen(200,snr=snr_train, rho=0.13)\n",
        "    x_true_all=torch.from_numpy(x_true_all_).float().to(device)\n",
        "    y_all=torch.from_numpy(y_all_).float().to(device)\n",
        "    input_x=torch.from_numpy(np.zeros_like(x_true_all_)).float().to(device)\n",
        "    outputs=model_AMP([input_x,y_all,y_all])\n",
        "    loss= criterion(outputs[i_layer][0],x_true_all)\n",
        "    #if i_epoch%5==0:\n",
        "    # print(\"layer: %2.0f i:%2.0f, loss:%f\"%(i_layer,i_epoch,loss.item()))\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "  max_iter_2=i_layer\n",
        "#   for param in model_AMP.model_list[i_layer].parameters():\n",
        "#     param.requires_grad_(False)\n",
        "   "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 31s, sys: 3min 3s, total: 7min 35s\n",
            "Wall time: 3min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcHyl5S-GJpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i_layer in range(num_layers):\n",
        "  for param in model_AMP.model_list[i_layer].parameters():\n",
        "      param.requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3xuDsUhJYLk",
        "colab_type": "code",
        "outputId": "27a8e428-a773-4294-b665-d84ea59f7342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#max_iter_2=8\n",
        "def error_prob_detect(x,x_hat, thresh_x_hat=10, thresh_x=1e-2):\n",
        "    ind_x_true= (np.abs(x)>thresh_x).astype(np.float64)\n",
        "    ind_x_hat=((x_hat)>thresh_x_hat).astype(np.float64)\n",
        "    f_a= np.sum(np.abs(ind_x_hat)*(1-ind_x_true))/np.sum(1-ind_x_true)\n",
        "    m_d=np.sum(np.abs(1-ind_x_hat)*(ind_x_true))/np.sum(ind_x_true)\n",
        "    return f_a,m_d\n",
        "\n",
        "x_true_all, y_all=data_gen(1000)\n",
        "num_snr=10\n",
        "snr_list=np.linspace(0,30,num_snr)\n",
        "mse_list= [0]*max_iter_2\n",
        "rho_list=np.linspace(0.01,0.2,num_snr)\n",
        "list_lists=[mse_list,rho_list,snr_list]\n",
        "plot_index=0\n",
        "fa_list_snr= [0]*len(snr_list)\n",
        "md_list_snr=[0]*len(snr_list)\n",
        "fa_list_iter= [0]*(max_iter_2)\n",
        "md_list_iter= [0]*(max_iter_2)\n",
        "fa_list_rho= [0]*len(snr_list)\n",
        "md_list_rho=[0]*len(snr_list)\n",
        "if plot_index==0:\n",
        "  err_list= [0]*(max_iter_2)\n",
        "else:\n",
        "  err_list= [0]*len(snr_list)\n",
        "x1=np.linalg.norm(x_true_all)\n",
        "x_norm=np.mean(x_true_all**2)\n",
        "num_avg=10\n",
        "for i_list,_ in enumerate(list_lists[plot_index]):\n",
        "        n_sims_plot=500\n",
        "        if plot_index==0:\n",
        "          x_true_all_, y_all_=data_gen(n_sims_plot, snr=30, rho=0.10)\n",
        "          y_all=torch.from_numpy(y_all_).float().to(device)\n",
        "          input_x=torch.from_numpy(np.zeros_like(x_true_all_)).float().to(device)\n",
        "          outputs=model_AMP([input_x,y_all,y_all])\n",
        "          z=outputs[i_list][0].cpu().detach().numpy()\n",
        "          err_list[i_list]+= np.mean((x_true_all_-z)**2)/np.mean(x_true_all_**2)\n",
        "#           fa_list_iter[i_list], md_list_iter[i_list] = error_prob_detect(x_norm_1,z_norm, thresh_x=0.00001, thresh_x_hat=0.1)\n",
        "          \n",
        "        elif plot_index==2:\n",
        "          x_true_all, y_all=data_gen(n_sims_plot, snr=10, rho=rho_list[i_list])\n",
        "          input_x=np.zeros_like(x_true_all)\n",
        "          z=Models_list[max_iter_2].predict([input_x,y_all,y_all])\n",
        "          z_norm= norm_vector(z)\n",
        "          x_norm_1= norm_vector(x_true_all)\n",
        "          err_list[i_list]+= np.sum((x_true_all-z)**2)*(0.1)**2/(x_norm*n_sims_plot*rho_list[i_list]**2)\n",
        "          fa_list_rho[i_list], md_list_rho[i_list] = error_prob_detect(x_norm_1,z_norm, thresh_x=0.00001, thresh_x_hat=0.001)\n",
        "          \n",
        "          \n",
        "        elif plot_index==1:  \n",
        "          x_true_all, y_all=data_gen(n_sims_plot//4, snr=snr_list[i_list], rho=0.1)\n",
        "          input_x=np.zeros_like(x_true_all)\n",
        "          z=Models_list[max_iter_2].predict([input_x,y_all,y_all])\n",
        "          z_norm= norm_vector(z)\n",
        "          x_norm_1= norm_vector(x_true_all)\n",
        "          err_list[i_list]+= 2*np.sum((x_true_all-z)**2)/(x_norm*n_sims_plot)\n",
        "          fa_list_snr[i_list], md_list_snr[i_list] = error_prob_detect(x_norm_1,z_norm, thresh_x=0.00001, thresh_x_hat=0.1)\n",
        "        \n",
        "        \n",
        "\n",
        "if plot_index==0:\n",
        "  plt.semilogy(err_list)\n",
        "  plt.title('MSE vs iter at 30dB, p=0.1')\n",
        "  plt.xlabel('iter')\n",
        "  plt.ylabel('MSE')\n",
        "  plt.grid()\n",
        "\n",
        "elif plot_index==1:\n",
        "  plt.semilogy(snr_list,err_list)\n",
        "  plt.title('MSE vs SNR at p=0.1')\n",
        "  plt.xlabel('SNR')\n",
        "  plt.ylabel('MSE')\n",
        "  plt.grid()\n",
        "  \n",
        "\n",
        "elif plot_index==2:\n",
        "  plt.semilogy(rho_list,err_list)\n",
        "  plt.title('MSE vs p at SNR=30dB')\n",
        "  plt.xlabel('p')\n",
        "  plt.ylabel('MSE')\n",
        "  plt.grid()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cGvO8En67Da",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "b20d4c6c-4712-4209-d041-dedd444a2d9d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Oct 29 00:49:37 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    58W / 149W |    645MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkfNJvGj_bn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
